# AIROGS Baseline - Guide de DÃ©marrage Rapide

## ğŸ“ Structure du Projet

Voici les fichiers que j'ai crÃ©Ã©s pour votre baseline AIROGS :

### Fichiers Python
1. **config.py** - Configuration centrale (paramÃ¨tres, chemins, hyperparamÃ¨tres)
2. **dataset.py** - Chargement et prÃ©traitement des donnÃ©es
3. **model.py** - Architecture du modÃ¨le (EfficientNet-B0 baseline)
4. **evaluation.py** - MÃ©triques d'Ã©valuation (pAUC, sensibilitÃ© @ 95% spÃ©cificitÃ©)
5. **train.py** - Script d'entraÃ®nement principal
6. **inference.py** - Script d'infÃ©rence
7. **utils.py** - Fonctions utilitaires (visualisation, vÃ©rification des donnÃ©es)

### Scripts SLURM pour Cluster
1. **train_cluster.sh** - Script SBATCH pour entraÃ®nement complet (20 epochs, ~2h)
2. **train_cluster_quick.sh** - Script SBATCH pour test rapide (5 epochs, ~30min)

### Autres Fichiers
1. **requirements.txt** - DÃ©pendances Python
2. **setup.sh** - Script de configuration automatique
3. **README.md** - Documentation complÃ¨te

## ğŸš€ Utilisation

### Option 1 : EntraÃ®nement sur Cluster (RECOMMANDÃ‰)

```bash
# 1. Se connecter au cluster
ssh votre_username@cluster.address

# 2. Aller dans le rÃ©pertoire du projet
cd /home/matteo/Bureau/FIB/cours/DLMA/MiccaiChallenge

# 3. Configurer l'environnement (premiÃ¨re fois seulement)
./setup.sh

# 4. IMPORTANT : Modifier train_cluster.sh avec vos informations
#    - Nom de la partition GPU de votre cluster
#    - Modules Ã  charger (python, cuda, cudnn)
#    - Votre email pour les notifications
nano train_cluster.sh

# 5. Soumettre le job
sbatch train_cluster.sh

# 6. VÃ©rifier le statut
squeue -u $USER

# 7. Suivre les logs en temps rÃ©el
tail -f logs/airogs_baseline_*.out
```

### Option 2 : EntraÃ®nement Local

```bash
# 1. Installer les dÃ©pendances
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# 2. Lancer l'entraÃ®nement
python train.py
```

## âš™ï¸ Configuration du Cluster

**IMPORTANT** : Avant de soumettre votre job, vous devez adapter `train_cluster.sh` Ã  votre cluster :

```bash
# Ouvrir le fichier
nano train_cluster.sh

# Modifier ces lignes selon votre cluster :
#SBATCH --partition=gpu          # â† Nom de votre partition GPU
#SBATCH --mail-user=votre@email  # â† Votre email

# Et ces lignes selon les modules disponibles :
module load python/3.9   # â† Version Python disponible
module load cuda/11.8    # â† Version CUDA disponible
module load cudnn/8.6    # â† Version cuDNN disponible
```

Pour connaÃ®tre les modules disponibles sur votre cluster :
```bash
module avail python
module avail cuda
module avail cudnn
```

## ğŸ“Š DonnÃ©es Attendues

Le script s'attend Ã  trouver :

```
data/
â”œâ”€â”€ 0/                      # Images d'entraÃ®nement
â”‚   â”œâ”€â”€ TRAIN000000.jpg
â”‚   â”œâ”€â”€ TRAIN000001.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ train_labels.csv        # Labels
```

Le fichier CSV doit contenir :
- `challenge_id` : ID de l'image (ex: TRAIN000000)
- `class` : Label (RG ou NRG)

## ğŸ¯ CaractÃ©ristiques du Baseline

### Architecture
- **Backbone** : EfficientNet-B0 (prÃ©-entraÃ®nÃ© ImageNet)
- **Input** : Images 384Ã—384 RGB
- **Output** : Classification binaire (RG vs NRG)
- **TÃªte de classification** : 3 couches denses avec dropout

### Gestion du DÃ©sÃ©quilibre de Classes
- Ratio RG:NRG â‰ˆ 1:30
- Solution : Loss pondÃ©rÃ©e (poids 30:1)

### Augmentation de DonnÃ©es
- Flip horizontal
- Rotation (Â±15Â°)
- Zoom (Â±10%)
- Ajustement de luminositÃ© (Â±20%)

### MÃ©triques d'Ã‰valuation (Challenge AIROGS)
- **Î± (pAUC)** : AUC partielle Ã  90-100% spÃ©cificitÃ©
- **Î²** : SensibilitÃ© Ã  95% de spÃ©cificitÃ©
- **Î³ (Kappa)** : Cohen's kappa pour gradabilitÃ© (placeholder)
- **Î´ (AUC)** : AUC pour dÃ©tection d'images non-gradables (placeholder)

## ğŸ“ˆ RÃ©sultats Attendus

Pour ce baseline simple :
- **AUC** : 0.80-0.85
- **pAUC (90-100% spec)** : 0.75-0.80
- **SensibilitÃ© @ 95% spec** : 0.65-0.75
- **Temps d'entraÃ®nement** : 1.5-2h (1 GPU)

*Note : Les gagnants du challenge ont atteint >0.90 pAUC avec des techniques avancÃ©es*

## ğŸ”§ Personnalisation

### Modifier les HyperparamÃ¨tres

Ã‰ditez `config.py` :

```python
IMAGE_SIZE = 384          # Taille des images
BATCH_SIZE = 32           # Taille du batch
EPOCHS = 20               # Nombre d'epochs
LEARNING_RATE = 1e-4      # Taux d'apprentissage
MODEL_BACKBONE = "efficientnet-b0"  # Architecture
```

### Changer d'Architecture

Dans `train.py` ou via arguments :

```bash
python train.py --backbone resnet50
# ou
python train.py --backbone efficientnet-b3
```

## ğŸ“ Sorties GÃ©nÃ©rÃ©es

AprÃ¨s l'entraÃ®nement, vous trouverez :

```
outputs/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ airogs_baseline_efficientnet-b0_YYYYMMDD_HHMMSS_best.h5
â”‚   â””â”€â”€ airogs_baseline_efficientnet-b0_YYYYMMDD_HHMMSS_final.h5
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ airogs_baseline_efficientnet-b0_YYYYMMDD_HHMMSS_training.csv
â”‚   â””â”€â”€ airogs_baseline_efficientnet-b0_YYYYMMDD_HHMMSS_history.json
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ *_roc.png
â”‚   â”œâ”€â”€ *_confusion.png
â”‚   â””â”€â”€ *_distribution.png
â””â”€â”€ airogs_baseline_efficientnet-b0_YYYYMMDD_HHMMSS_results.json
```

## ğŸ” InfÃ©rence

```bash
# Image unique
python inference.py \
    --model outputs/models/votre_modele_best.h5 \
    --image chemin/vers/image.jpg

# Batch d'images
python inference.py \
    --model outputs/models/votre_modele_best.h5 \
    --image-dir chemin/vers/images/ \
    --output predictions.csv
```

## ğŸ› DÃ©pannage

### Out of Memory (OOM)
RÃ©duisez le batch size dans `config.py` :
```python
BATCH_SIZE = 16  # ou 8
```

### EntraÃ®nement Trop Lent
RÃ©duisez la taille des images :
```python
IMAGE_SIZE = 256
```

### ProblÃ¨me avec les Modules du Cluster
Listez les modules disponibles :
```bash
module avail
```

## ğŸ“š AmÃ©liorations Possibles (Semaine 2+)

### OrientÃ©es DonnÃ©es
1. Augmentation avancÃ©e (MixUp, CutMix)
2. DÃ©tection et crop du disque optique
3. PrÃ©-traitement spÃ©cifique fundus
4. Ã‰quilibrage avancÃ© (Focal Loss, SMOTE)

### OrientÃ©es ModÃ¨le
1. Architectures plus grandes (EfficientNet-B3, ResNet-101)
2. Multi-task learning (glaucome + gradabilitÃ©)
3. Test-time augmentation
4. Estimation d'incertitude (MC Dropout)

### OrientÃ©es EntraÃ®nement
1. Optimiseurs avancÃ©s (AdamW, LAMB)
2. Learning rate schedules
3. Cross-validation K-fold

## ğŸ“ Support

Pour toute question sur :
- Les mÃ©triques du challenge : voir `evaluation.py`
- L'architecture : voir `model.py`
- Le prÃ©traitement : voir `dataset.py`
- La documentation complÃ¨te : voir `README.md`

## âœ… Checklist Avant Soumission

- [ ] DonnÃ©es placÃ©es dans `data/0/` et `data/train_labels.csv`
- [ ] Script `train_cluster.sh` configurÃ© avec vos paramÃ¨tres cluster
- [ ] Environnement virtuel crÃ©Ã© et dÃ©pendances installÃ©es
- [ ] Test rapide effectuÃ© avec `train_cluster_quick.sh`
- [ ] Logs vÃ©rifiÃ©s (pas d'erreurs)
- [ ] RÃ©sultats Ã©valuÃ©s (mÃ©triques affichÃ©es)

Bon courage ! ğŸš€

